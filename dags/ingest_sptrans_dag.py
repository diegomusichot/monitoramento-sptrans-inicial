"""
DAG respons√°vel pela ingest√£o dos dados da API Olho Vivo (SPTrans)
-----------------------------------------------------------------
Objetivo:
Executar a coleta de posi√ß√µes de √¥nibus a cada 2 minutos,
utilizando o script Python localizado em /opt/airflow/scripts/ingest_sptrans.py

Destaques:
- Executa automaticamente a cada 2 minutos (cron)
- Reexecuta em caso de falha (retries)
- Define tempo m√°ximo de execu√ß√£o (timeout)
- Impede execu√ß√µes simult√¢neas (max_active_runs)
- Aplica boas pr√°ticas de robustez e organiza√ß√£o
"""

# Importa√ß√µes necess√°rias
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.bash import BashOperator

# ------------------------------------------------------------
#CONFIGURA√á√ïES PADR√ÉO DA DAG
# ------------------------------------------------------------
# Esses par√¢metros valem para todas as tasks dentro da DAG.
# Eles controlam comportamento em caso de falha, tempo de espera e depend√™ncias.
default_args = {
    "depends_on_past": False,               # Cada execu√ß√£o √© independente (n√£o depende da anterior)
    "retries": 3,                           # N√∫mero de tentativas em caso de falha
    "retry_delay": timedelta(seconds=45),   # Tempo entre as tentativas
}

# ------------------------------------------------------------
# DEFINI√á√ÉO DA DAG
# ------------------------------------------------------------
# Aqui definimos as propriedades principais da DAG ‚Äî nome, agendamento e pol√≠ticas.
with DAG(
    dag_id="ingest_sptrans_cada_2_min",     # Nome √∫nico da DAG (como ser√° exibido no Airflow)
    description="Ingest√£o da API Olho Vivo (SPTrans) a cada 2 minutos ‚Äì camada Bronze",
    start_date=datetime(2025, 10, 1),       # Data inicial de refer√™ncia (n√£o retroage)
    schedule="*/2 * * * *",                 # Executa a cada 2 minutos (formato cron)
    catchup=False,                          # N√£o reexecuta per√≠odos antigos ao ativar a DAG
    default_args=default_args,              # Aplica as configura√ß√µes definidas acima
    max_active_runs=1,                      # Impede execu√ß√µes simult√¢neas (evita sobreposi√ß√£o)
    tags=["sptrans", "bronze", "ingestao"], # Facilita busca e categoriza√ß√£o na UI do Airflow
) as dag:

    # ------------------------------------------------------------
    # TASK: Executar o script de ingest√£o
    # ------------------------------------------------------------
    # Essa task chama diretamente o script Python que realiza a coleta dos dados.
    # O comando "set -euo pipefail" garante que qualquer erro no script cause falha imediata.
    ingest = BashOperator(
        task_id="ingest_posicao",  # Identificador da task (√∫nico dentro da DAG)
        bash_command=(
            "set -euo pipefail; "  # Torna o bash mais seguro (erro ‚Üí interrompe execu√ß√£o)
            "python /opt/airflow/scripts/ingest_sptrans.py"
        ),
        # Tempo m√°ximo permitido para execu√ß√£o da task
        execution_timeout=timedelta(minutes=2),

        # Configura√ß√£o de nova tentativa com backoff exponencial
        retry_exponential_backoff=True,       # Aumenta o tempo entre as tentativas (progressivo)
        max_retry_delay=timedelta(minutes=3), # Tempo m√°ximo entre as tentativas

        # SLA (Service Level Agreement): alerta visual na UI caso ultrapasse 1 minuto
        # Isso n√£o envia e-mails ‚Äî apenas exibe um aviso na interface.
        sla=timedelta(minutes=1),

        # Vari√°veis de ambiente adicionais (opcional)
        # Exemplo: passar timezone ou vari√°veis definidas no Airflow
        # env={"TZ": "America/Sao_Paulo"},
    )

    # ------------------------------------------------------------
    # üîó DEPEND√äNCIAS (se existissem outras tasks)
    # ------------------------------------------------------------
    # Neste caso, temos apenas uma task, ent√£o ela roda sozinha.
    ingest
